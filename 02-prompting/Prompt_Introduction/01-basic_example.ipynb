{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4238cef9",
   "metadata": {},
   "source": [
    "## Introducción al diseño de estrategias de prompting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c36848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias necesarias para el proyecto \n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from enum import Enum\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3029036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargando las variables de entorno \n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986be547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diseñando una Clase para manejar diferentes tipos de modelos \n",
    "# Nos enfocaremos en OpenAI\n",
    "\n",
    "class OpenAIModels(str,Enum): # Str -> Para que los valores sean cadenas de texto # Enum -> Para crear una enumeración\n",
    "    GPT_4o = \"gpt-4o\"\n",
    "    GPT_4o_mini = \"gpt-4o-mini\"\n",
    "    GPT_5_mini = \"gpt-5-mini\"\n",
    "\n",
    "MODEL = OpenAIModels.GPT_5_mini # Seleccionando el modelo a utilizar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3345519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una funcion wrapper para tener el llamado de OPenAI y sus componentes orquestados \n",
    "\n",
    "def get_completion(system_prompt, # Define el comportamiento del modelo\n",
    "                   user_prompt,  # Es ;la solicitud del usuario\n",
    "                   model=MODEL):\n",
    "\n",
    "    # Construcción de los mensajes \n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "    if system_prompt is not None:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            *messages,\n",
    "        ]\n",
    "    try:\n",
    "        # LLamado a la API de OpenAI\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=None, # Controla la creatividad de las respuestas\n",
    "        )\n",
    "        return response.choices[0].message.content # DEvuelve solo el cuerpo de la respuesta , no toda la metadata\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774b1756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_responses(*args):\n",
    "    \"\"\"AYuda visual en formato markdown para comparar los modelos.\"\"\"\n",
    "    markdown_string = \"<table><tr>\"\n",
    "    for arg in args:\n",
    "        markdown_string += f\"<th>System Prompt:<br />{arg['system_prompt']}<br /><br />\"\n",
    "        markdown_string += f\"User Prompt:<br />{arg['user_prompt']}</th>\"\n",
    "    markdown_string += \"</tr>\"\n",
    "    markdown_string += \"<tr>\"\n",
    "    for arg in args:\n",
    "        markdown_string += f\"<td>Response:<br />{arg['response']}</td>\"\n",
    "    markdown_string += \"</tr></table>\"\n",
    "    display(Markdown(markdown_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae414753",
   "metadata": {},
   "source": [
    "### Estrategias y comparativas de Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b298216",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"Eres un asistente útil y creativo , en temas de coqueteo y relaciones amorosas respetuosas.\"\n",
    "user_prompt = \"Escribe un mensaje coqueto para invitar a salir a alguien que te gusta.\"\n",
    "\n",
    "print('=='*32)\n",
    "print(f'Enviar solicitud al modelo:  {MODEL}')\n",
    "baseline_response = get_completion(system_prompt, user_prompt)\n",
    "print('=='*32)\n",
    "display_responses({\n",
    "    \"system_prompt\": system_prompt,\n",
    "    \"user_prompt\": user_prompt, \n",
    "    \"response\": baseline_response\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc71ea7",
   "metadata": {},
   "source": [
    "### Agregandole un ROl más profesional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e7aac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_system_prompt = \"Eres un experto en seducción , relaciones amorosas y extremadamente latino. Usas la poesia y la mistica de la música para conquistar. Tambien eres un experto en cocina y sabes como combinar platos y bebidas para un fin romántico.\"\n",
    "\n",
    "print(\"==\"*32)\n",
    "role_response = get_completion(role_system_prompt, user_prompt)\n",
    "print(\"==\"*32)\n",
    "display_responses(\n",
    "    {\n",
    "        \"system_prompt\": system_prompt,\n",
    "        \"user_prompt\": user_prompt,\n",
    "        \"response\": baseline_response\n",
    "    },  \n",
    "    {\n",
    "        \"system_prompt\": role_system_prompt,    \n",
    "        \"user_prompt\": user_prompt,\n",
    "        \"response\": role_response\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c58e4e9",
   "metadata": {},
   "source": [
    "### Agregando restricciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eff5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints_system_prompt = f\"\"\"\n",
    "                             {role_system_prompt}. Solo tienes tiempo para cocinar el Jueves a las 8 PM, porque después quitaran el gas en tu edificio. Como presupuesto para la cena tienes 50 dólares.\n",
    "                             No recomiendes un postre , dado que por la hora no habrá tiempo para prepararlo.\n",
    "                             \"\"\"\n",
    "\n",
    "print(\"==\"*32)\n",
    "constraints_response = get_completion(constraints_system_prompt, user_prompt)\n",
    "print(\"==\"*32)\n",
    "display_responses(\n",
    "    {\n",
    "        \"system_prompt\": system_prompt,\n",
    "        \"user_prompt\": user_prompt,\n",
    "        \"response\": baseline_response\n",
    "    },  \n",
    "    {\n",
    "        \"system_prompt\": role_system_prompt,    \n",
    "        \"user_prompt\": user_prompt,\n",
    "        \"response\": role_response\n",
    "    },\n",
    "    {\n",
    "        \"system_prompt\": constraints_system_prompt,    \n",
    "        \"user_prompt\": user_prompt, \n",
    "        \"response\": constraints_response\n",
    "    },)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brief-ai-vs-software-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
